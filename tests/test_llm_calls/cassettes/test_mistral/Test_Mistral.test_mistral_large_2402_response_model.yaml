interactions:
- request:
    body: '{"messages": [{"role": "user", "content": "Tell me a joke"}], "llm_providers":
      [{"provider": "mistral", "model": "mistral-large-2402", "is_custom": false,
      "context_length": null, "input_price": null, "output_price": null, "latency":
      null}], "metric": "accuracy", "max_model_depth": 1, "hash_content": true}'
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '306'
      User-Agent:
      - Python-SDK/0.3.20
      content-type:
      - application/json
    method: POST
    uri: https://not-diamond-server-oqbj.onrender.com/v2/modelRouter/modelSelect
  response:
    body:
      string: '{"providers":[{"provider":"mistral","model":"mistral-large-2402"}],"session_id":"84967de8-02e0-4ab8-891d-64b55e128f6e"}'
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 8d107fa3ca80a4f8-MIA
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Fri, 11 Oct 2024 17:16:33 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      alt-svc:
      - h3=":443"; ma=86400
      rndr-id:
      - 90f14e95-e37a-4ec2
      x-api-key:
      - REDACTED
      x-render-origin-server:
      - uvicorn
      x-token:
      - REDACTED
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "The output should be formatted
      as a JSON instance that conforms to the JSON schema below.\n\nAs an example,
      for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\":
      \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}},
      \"required\": [\"foo\"]}\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted
      instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}}
      is not well-formatted.\n\nHere is the output schema:\n```\n{\"properties\":
      {\"setup\": {\"description\": \"question to set up a joke\", \"title\": \"Setup\",
      \"type\": \"string\"}, \"punchline\": {\"description\": \"answer to resolve
      the joke\", \"title\": \"Punchline\", \"type\": \"string\"}}, \"required\":
      [\"setup\", \"punchline\"]}\n```\nTell me a joke"}], "model": "mistral-large-2402",
      "temperature": 0.7, "max_tokens": 200, "top_p": 1, "safe_prompt": false, "stream":
      false}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '966'
      content-type:
      - application/json
      host:
      - api.mistral.ai
      user-agent:
      - python-httpx/0.27.2
    method: POST
    uri: https://api.mistral.ai/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA0SQwW7bMBBEf4WZSy9METOKrfBSID+RQxUYK3JrMaFIgbsqYhj+90AI3F4H8wYz
        c0GK8Ng5Ojz2T/HQudhRYHrqXRdp7GikfnQRFnV856DwCBPpz1DnJbOmWmARGpNyhN8dXL/f75+f
        O4u5Rs7wmJNoo3yfqZ343nUPbiOmmgIL/O8LUon8Cf9gMbMInRj+glYzw4NEkigV3ZhalMvW4DIU
        YwYI67oM8GbA63Q2sZYfaiQkLppExWhbRQ1pneXXAPsNLWsJU06Fv8EXDrQKG534bGb6YLMuhv9y
        O+uUyuluwFCusNBa8zFQzgJf1pyvFn9SSTIdG5PUAg/RusAi19PS6njzvVmst1FLq/OiR60fXATe
        7fZbsFL+L3X9NvT27T/90V2vXwAAAP//AwAt8SRAqwEAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8d107fa8f99c0a02-MIA
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Fri, 11 Oct 2024 17:16:35 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      ratelimitbysize-limit:
      - '20000000'
      ratelimitbysize-query-cost:
      - '336'
      ratelimitbysize-remaining:
      - '19997744'
      ratelimitbysize-reset:
      - '26'
      x-api-key:
      - REDACTED
      x-envoy-upstream-service-time:
      - '829'
      x-kong-proxy-latency:
      - '1'
      x-kong-request-id:
      - 0f7e3d659af94b195a878853160f002f
      x-kong-upstream-latency:
      - '829'
      x-ratelimitbysize-limit-minute:
      - '20000000'
      x-ratelimitbysize-limit-month:
      - '200000000000'
      x-ratelimitbysize-remaining-minute:
      - '19997744'
      x-ratelimitbysize-remaining-month:
      - '199861761447'
      x-token:
      - REDACTED
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "Tell me a joke"}], "llm_providers":
      [{"provider": "mistral", "model": "mistral-large-2402", "is_custom": false,
      "context_length": null, "input_price": null, "output_price": null, "latency":
      null}], "metric": "accuracy", "max_model_depth": 1, "hash_content": true}'
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '306'
      User-Agent:
      - Python-SDK/0.3.20
      content-type:
      - application/json
    method: POST
    uri: https://staging-api.notdiamond.ai/v2/modelRouter/modelSelect
  response:
    body:
      string: '{"providers":[{"provider":"mistral","model":"mistral-large-2402"}],"session_id":"4658469f-1b15-4068-91e8-868c4a9ad375"}'
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 8d28c79ceefb8df7-MIA
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Mon, 14 Oct 2024 16:00:00 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      alt-svc:
      - h3=":443"; ma=86400
      rndr-id:
      - 60a402f1-6a6c-4fbc
      x-api-key:
      - REDACTED
      x-render-origin-server:
      - uvicorn
      x-token:
      - REDACTED
    status:
      code: 200
      message: OK
version: 1
