interactions:
- request:
    body: '{"messages": [{"role": "user", "content": "Tell me a joke"}], "llm_providers":
      [{"provider": "mistral", "model": "mistral-large-latest", "is_custom": false,
      "context_length": null, "input_price": null, "output_price": null, "latency":
      null}], "metric": "accuracy", "max_model_depth": 1, "hash_content": true}'
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '308'
      User-Agent:
      - Python-SDK/0.3.20
      content-type:
      - application/json
    method: POST
    uri: https://not-diamond-server-oqbj.onrender.com/v2/modelRouter/modelSelect
  response:
    body:
      string: '{"providers":[{"provider":"mistral","model":"mistral-large-latest"}],"session_id":"a52ab70f-56be-4fad-9c65-6501d828fc9e"}'
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 8d107f0e7af731e3-MIA
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Fri, 11 Oct 2024 17:16:10 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      alt-svc:
      - h3=":443"; ma=86400
      rndr-id:
      - 0c1400f9-76cf-4be5
      x-api-key:
      - REDACTED
      x-render-origin-server:
      - uvicorn
      x-token:
      - REDACTED
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "The output should be formatted
      as a JSON instance that conforms to the JSON schema below.\n\nAs an example,
      for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\":
      \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}},
      \"required\": [\"foo\"]}\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted
      instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}}
      is not well-formatted.\n\nHere is the output schema:\n```\n{\"properties\":
      {\"setup\": {\"description\": \"question to set up a joke\", \"title\": \"Setup\",
      \"type\": \"string\"}, \"punchline\": {\"description\": \"answer to resolve
      the joke\", \"title\": \"Punchline\", \"type\": \"string\"}}, \"required\":
      [\"setup\", \"punchline\"]}\n```\nTell me a joke"}], "model": "mistral-large-latest",
      "temperature": 0.7, "max_tokens": 200, "top_p": 1, "safe_prompt": false, "stream":
      false}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '968'
      content-type:
      - application/json
      host:
      - api.mistral.ai
      user-agent:
      - python-httpx/0.27.2
    method: POST
    uri: https://api.mistral.ai/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA0TQwU6EQBAE0F+Z1BkN4LqLczF+hQfHLM3QLKNDD2GaRLPh3w0a9VrJq1T3FaGH
        RVOXta+q6kBleSB/6hpf1oMfuq55qLqhQoHUvbFXWPiR9NanaY6sIQkK+IVJuYetTnVzPB4fTmWB
        KfUcYTGFrAvFm0jLhW8iKWfdzZiC5wz7ckWQnj9gd8Q504Vhr1hSZFhQziErybdJoiz7hrZt33IS
        J1cnxjhk1nV2sMbheSQ1fTKfaTWeYjQDvbPJM11GVg2PDsWPmVfxYwzCP+5JTJhmykq3Dk42J23b
        ooCmFM97UYaVNcatwBAk5PG8MOUksMiaZmyvBdbf8fOSplnPmt5ZMmxdHfcipfgf3R/2g36/+Jff
        Ndv2BQAA//8DAFsXrVuVAQAA
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8d107f147a2267c9-MIA
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Fri, 11 Oct 2024 17:16:14 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      ratelimitbysize-limit:
      - '20000000'
      ratelimitbysize-query-cost:
      - '336'
      ratelimitbysize-remaining:
      - '19999248'
      ratelimitbysize-reset:
      - '50'
      x-api-key:
      - REDACTED
      x-envoy-upstream-service-time:
      - '4059'
      x-kong-proxy-latency:
      - '1'
      x-kong-request-id:
      - 1394a275bb45cd7cb1ecf45aa9cc725f
      x-kong-upstream-latency:
      - '4059'
      x-ratelimitbysize-limit-minute:
      - '20000000'
      x-ratelimitbysize-limit-month:
      - '200000000000'
      x-ratelimitbysize-remaining-minute:
      - '19999248'
      x-ratelimitbysize-remaining-month:
      - '199861761163'
      x-token:
      - REDACTED
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "Tell me a joke"}], "llm_providers":
      [{"provider": "mistral", "model": "mistral-large-latest", "is_custom": false,
      "context_length": null, "input_price": null, "output_price": null, "latency":
      null}], "metric": "accuracy", "max_model_depth": 1, "hash_content": true}'
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '308'
      User-Agent:
      - Python-SDK/0.3.20
      content-type:
      - application/json
    method: POST
    uri: https://staging-api.notdiamond.ai/v2/modelRouter/modelSelect
  response:
    body:
      string: '{"providers":[{"provider":"mistral","model":"mistral-large-latest"}],"session_id":"97d440b5-11b0-4396-812e-5f8f1a39b699"}'
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-Ray:
      - 8d28c77d1f7474b0-MIA
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Mon, 14 Oct 2024 15:59:55 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      alt-svc:
      - h3=":443"; ma=86400
      rndr-id:
      - 02350ec5-850e-44e1
      x-api-key:
      - REDACTED
      x-render-origin-server:
      - uvicorn
      x-token:
      - REDACTED
    status:
      code: 200
      message: OK
version: 1
